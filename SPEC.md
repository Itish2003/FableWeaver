# Project Name: FableWeaver (Interactive Fiction Engine)

**Version:** 1.0
**Framework:** Google Agent Development Kit (ADK) / Vertex AI
**Architecture Pattern:** Human-in-the-Loop Recursive Pipeline

---

## 1. Executive Overview

**FableWeaver** is an AI-orchestrated creative writing engine designed to generate high-fidelity fanfiction. Unlike standard LLM chat interfaces, this system maintains a **Single Source of Truth (SSOT)** regarding world state and utilizes a **Deep Research Pipeline** to ensure canonical accuracy (lore compliance) across multiple source materials (e.g., High School DxD, Fate Series).

The system operates on a "Fan-out / Fan-in" architecture where parallel agents gather context, a synthesizer unifies it, and a narrative agent generates prose based on user-selected branches.

---

## 2. Input Specifications (The "Brief")

The system initializes via a configuration object provided by the user:

1.  **Source Material (The Universe):**
    - Target fandoms (e.g., "High School DxD", "Fate/Stay Night").
    - _Requirement:_ System must be able to research these independently.
2.  **Character Model (The OC):**
    - Name, Gender, Personality Archetype (e.g., "Cold/Manipulative").
    - Starting Abilities/Race.
3.  **World Parameters (The Setting):**
    - Timeline Deviation (e.g., "500 years pre-canon").
    - Specific Setting Rules (e.g., "Great War Era," "Hellish Landscape").

---

## 3. Data Architecture: The World Bible

To maintain consistency across long sessions, the system relies on a persistent JSON file. No agent retains state in RAM; all state is retrieved from this file.

**File:** `world_bible.json`

```json
{
  "meta": {
    "title": "The Azure War",
    "timeline_year": "1450 AD",
    "universes": ["DxD", "Fate"]
  },
  "character_sheet": {
    "name": "Kael",
    "archetype": "Villain Protagonist",
    "status": { "hp": "100%", "mana": "High" },
    "inventory": ["Broken Phantasm", "Devil Chess Piece"],
    "relationships": { "Azazel": "Neutral", "Zelretch": "Hostile" }
  },
  "world_state": {
    "active_locations": ["Kyoto", "Underworld"],
    "global_flags": {
      "great_war_active": true,
      "kyoto_barrier_status": "Active"
    }
  },
  "narrative_memory": {
    "last_chapter_summary": "...",
    "key_decisions": ["Chose to betray the devils in Ch2"]
  }
}
```

---

## 4. System Architecture: The Agent Pipeline

The application is structured as a nested `SequentialAgent` containing a `ParallelAgent`.

### Phase A: The Research Pipeline (Initialization)

#### 1. The LoreHunter Swarm (`ParallelAgent`)

- **Role:** Information Retrieval (Fan-Out).
- **Components:**
  - _Agent A (Source 1):_ "Search DxD Wiki for Great War mechanics."
  - _Agent B (Source 2):_ "Search Fate Wiki for Magic Circuit mechanics."
  - _Agent C (History):_ "Search 15th Century Japan politics."
- **Tools:** `google_search_grounding`, `url_scraper`.
- **Output:** A list of raw text blobs/summaries.

#### 2. The LoreKeeper (`SequentialAgent` - The Synthesizer)

- **Role:** Context Consolidation (Fan-In).
- **Input:** The raw list from the Swarm.
- **Instruction:** "You are the Archivist. Read these disparate research notes. Combine them into a cohesive set of 'World Rules.' Resolve conflicts (e.g., if Magic systems clash, prioritize Source A)."
- **Output:** Updates the `world_bible.json` with the initial world rules.

### Phase B: The Narrative Loop (Recursive)

#### 3. The Storyteller (`Agent`)

- **Role:** Prose Generation.
- **Input:** User Inputs + `world_bible.json` + `last_chapter_summary`.
- **Instruction:** "Write the next scene. Adhere strictly to the World Bible. Show, don't tell."
- **Tools:** `read_bible`.

#### 4. The Game Master (`Agent`)

- **Role:** State Management & Branching.
- **Input:** The text just generated by the Storyteller.
- **Process:**
  1.  **Summarize:** Condense the new chapter.
  2.  **Update State:** Did the MC get hurt? Did an NPC die? Call `update_bible`.
  3.  **Branch:** Generate 8-10 distinct options for the user.
- **Tools:** `read_bible`, `update_bible`.

---

## 5. Implementation Steps & Logic Flow

### Step 1: Tool Definitions

We must define Python functions that the Agents can call.

- `search_and_scrape(query)`: Uses Google Search API to find a relevant Wiki URL, then uses a scraper (BeautifulSoup) to fetch the text.
- `read_bible(key)`: Returns data from JSON.
- `write_bible(key, value)`: Updates the JSON safely.

### Step 2: The Initialization Flow (Code Logic)

```python
# Pseudo-code representation of the ADK structure

# 1. Define Parallel Researchers
dxd_researcher = Agent(name="dxd", tools=[search_and_scrape])
fate_researcher = Agent(name="fate", tools=[search_and_scrape])

# 2. Wrap in Parallel Block
research_swarm = ParallelAgent(
    agents=[dxd_researcher, fate_researcher],
    merge_strategy="append_results"
)

# 3. Define the Synthesizer (The "Fan-In" Agent)
lore_synthesizer = Agent(
    instruction="Synthesize raw research into a consistent World Bible context.",
    tools=[write_bible]
)

# 4. Define the Writer
writer = Agent(instruction="Write story based on Bible...", tools=[read_bible])

# 5. Define the Game Master
game_master = Agent(instruction="Update state and generate branches...", tools=[write_bible])

# 6. Create the Master Sequence
story_engine = SequentialAgent(
    agents=[
        research_swarm,    # Step 1: Run all searches
        lore_synthesizer,  # Step 2: Consolidate lore
        writer,            # Step 3: Write Chapter 1
        game_master        # Step 4: Logic & Options
    ]
)
```

### Step 3: The Interaction Loop

1.  **User** sends the prompt.
2.  **System** runs the `story_engine`.
3.  **System** outputs:
    - The Story Text (Chapter 1).
    - The Options (1-8).
4.  **User** selects Option 3.
5.  **System** injects "User selected Option 3" into the context.
6.  **System** triggers `writer` -> `game_master` loop again (skipping research unless new lore is needed).

---

## 6. Technology Stack

- **Core LLM:** **Gemini 1.5 Pro** (Selected for 1M+ token context window to hold massive lore files).
- **Orchestrator:** **Google ADK / LangGraph** (For stateful graph management).
- **Search Provider:** **Google Search Grounding (Vertex AI)**.
- **Scraper:** **Playwright** (Headless browser for reading modern JS-heavy wikis) or **BeautifulSoup** (for static wikis).
- **Database:** Local `JSON` (MVP) or **Firestore** (Scalable).
- **Runtime:** **Python 3.10+**.

---

## 7. Edge Cases & Solutions

- **Problem:** The agents research the wrong thing (e.g., "Fate" anime vs "Fate" destiny).
  - _Solution:_ Pre-prompt the Parallel Agents with specific context keywords (e.g., "Always append 'Type-Moon' to queries").
- **Problem:** The Bible becomes too large.
  - _Solution:_ Gemini 1.5 Pro handles large context, but the `LoreKeeper` should perform "Garbage Collection" every 5 chapters (summarizing old logs into a single paragraph).
- **Problem:** User picks a branch that breaks lore.
  - _Solution:_ The `Game Master` agent checks the user's choice against the `world_bible` before executing. If impossible, it narrates a failure or an adaptation.
